name: llama3
backend: llama-cpp
parameters:
  model: Hermes-3-Llama-3.2-3B-Q4_K_M.gguf
context_size: 2048
gpu_layers: 15
f16: true
use_mlock: false
use_mmap: true
