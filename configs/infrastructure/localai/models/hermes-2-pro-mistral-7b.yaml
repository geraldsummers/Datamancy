name: hermes-2-pro-mistral-7b
backend: llama-cpp
parameters:
  model: hermes-2-pro-mistral-7b.Q4_K_M.gguf
context_size: 4096
gpu_layers: 35
f16: true
use_mlock: false
use_mmap: true
download_files:
  - filename: hermes-2-pro-mistral-7b.Q4_K_M.gguf
    uri: https://huggingface.co/NousResearch/Hermes-2-Pro-Mistral-7B-GGUF/resolve/main/Hermes-2-Pro-Mistral-7B.Q4_K_M.gguf
