name: router
backend: llama-cpp
parameters:
  model: Hermes-3-Llama-3.2-3B-Q4_K_M.gguf
  context_size: 2048
  gpu_layers: 35
download_files:
  - filename: Hermes-3-Llama-3.2-3B-Q4_K_M.gguf
    uri: https://huggingface.co/NousResearch/Hermes-3-Llama-3.2-3B-GGUF/resolve/main/Hermes-3-Llama-3.2-3B-Q4_K_M.gguf
