model_list:
  # Main chat model - Hermes-2-Pro-Mistral-7B
  - model_name: hermes-2-pro-mistral-7b
    litellm_params:
      model: openai/hermes-2-pro-mistral-7b
      api_base: http://localai:8080/v1
      api_key: dummy
      max_tokens: 4096

  # Coding specialist
  - model_name: qwen-code
    litellm_params:
      model: openai/qwen-code
      api_base: http://localai:8080/v1
      api_key: dummy
      max_tokens: 4096

  # Router/triage model
  - model_name: router
    litellm_params:
      model: openai/router
      api_base: http://localai:8080/v1
      api_key: dummy
      max_tokens: 2048

  # Embeddings
  - model_name: embed-small
    litellm_params:
      model: openai/embed-small
      api_base: http://localai:8080/v1
      api_key: dummy

  # Vision/image understanding
  - model_name: vision
    litellm_params:
      model: openai/vision
      api_base: http://localai:8080/v1
      api_key: dummy

  # Speech-to-text (high quality)
  - model_name: whisper-medium
    litellm_params:
      model: openai/whisper-medium
      api_base: http://localai:8080/v1
      api_key: dummy

  # Speech-to-text (fast)
  - model_name: whisper-small
    litellm_params:
      model: openai/whisper-small
      api_base: http://localai:8080/v1
      api_key: dummy

  # Image generation
  - model_name: sd15
    litellm_params:
      model: openai/sd15
      api_base: http://localai:8080/v1
      api_key: dummy

litellm_settings:
  drop_params: true
  success_callback: []
  failure_callback: []

general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY
  database_url: os.environ/DATABASE_URL
  # Internal proxy - no SSO needed, auth via master key only
