# Auto-generated by build-datamancy.main.kts
# Image versions are HARDCODED at build time
# Only secrets and deployment paths use runtime ${VARS}

services:
  grafana:
    image: grafana/grafana:11.6.9
    container_name: grafana
    restart: unless-stopped
    networks:
      caddy:
        aliases:
          - grafana.${DOMAIN}
      postgres:
        aliases:
          - grafana.${DOMAIN}
      authelia:
        aliases:
          - grafana.${DOMAIN}
      monitoring:
        aliases:
          - grafana.${DOMAIN}
    depends_on:
      postgres:
        condition: service_started
      authelia:
        condition: service_started
    environment:
      GF_DEFAULT_LOCALE: en_US
      GF_SERVER_ROOT_URL: https://grafana.${DOMAIN}
      GF_SERVER_DOMAIN: grafana.${DOMAIN}
      GF_DATABASE_TYPE: postgres
      GF_DATABASE_HOST: postgres:5432
      GF_DATABASE_NAME: grafana
      GF_DATABASE_USER: grafana
      GF_DATABASE_PASSWORD: ${GRAFANA_DB_PASSWORD}
      GF_DATABASE_SSL_MODE: disable
      # Using Caddy forward_auth with Authelia (not OIDC)
      GF_AUTH_PROXY_ENABLED: true
      GF_AUTH_PROXY_HEADER_NAME: Remote-User
      GF_AUTH_PROXY_HEADER_PROPERTY: username
      GF_AUTH_PROXY_AUTO_SIGN_UP: true
      GF_AUTH_PROXY_HEADERS: "Email:Remote-Email Name:Remote-Name"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./configs/monitoring/grafana/provisioning/datasources:/etc/grafana/provisioning/datasources:ro
      - ./configs/monitoring/grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards:ro
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 60s

  prompt-server:
    image: nginx:alpine
    container_name: prompt-server
    restart: unless-stopped
    networks:
      caddy:
        aliases:
          - prompts.${DOMAIN}
    volumes:
      - ./configs/prompts:/usr/share/nginx/html:ro
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://localhost:80/README.md || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s

  open-webui:
    image: ghcr.io/open-webui/open-webui:0.4.6
    container_name: open-webui
    restart: unless-stopped
    networks:
      caddy:
        aliases:
          - open-webui.${DOMAIN}
      postgres:
        aliases:
          - open-webui.${DOMAIN}
      litellm:
        aliases:
          - open-webui.${DOMAIN}
      authelia:
        aliases:
          - open-webui.${DOMAIN}
    depends_on:
      postgres:
        condition: service_started
      litellm:
        condition: service_started
      authelia:
        condition: service_started
    environment:
      WEBUI_URL: ${OPENWEBUI_WEBUI_URL:-https://open-webui.${DOMAIN}}
      DATABASE_URL: postgresql://openwebui:${OPENWEBUI_DB_PASSWORD}@postgres:5432/openwebui
      ENABLE_OAUTH_SIGNUP: ${OPENWEBUI_ENABLE_OAUTH_SIGNUP:-true}
      DEFAULT_USER_ROLE: ${OPENWEBUI_DEFAULT_USER_ROLE:-admin}
      ENABLE_OPENAI_API: true
      OPENAI_API_BASE_URL: ${OPENWEBUI_OPENAI_API_BASE_URL:-http://litellm:4000/v1}
      OPENAI_API_KEY: ${LITELLM_MASTER_KEY}
      DEFAULT_MODELS: qwen2.5-7b-instruct
      # Smooth streaming for better UX
      STREAMING_CHUNK_SIZE: 1
      # Disable auto-downloading models from HuggingFace
      ENABLE_RAG_WEB_LOADER_SSL_VERIFICATION: false
      RAG_EMBEDDING_ENGINE: ollama
      RAG_RERANKING_MODEL: ""
      OPENID_PROVIDER_URL: https://auth.${DOMAIN}
      OAUTH_CLIENT_ID: open-webui
      OAUTH_CLIENT_SECRET: ${OPENWEBUI_OAUTH_SECRET}
      OAUTH_PROVIDER_NAME: Authelia
      OAUTH_SCOPES: openid profile email groups
      ENABLE_LOGIN_FORM: false
      WEBUI_AUTH: false
    volumes:
      - open_webui_data:/app/backend/data
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/health || exit 1"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 90s

  vaultwarden:
    image: vaultwarden/server:testing
    container_name: vaultwarden
    restart: unless-stopped
    networks:
      caddy:
        aliases:
          - vaultwarden.${DOMAIN}
          - app.vaultwarden.${DOMAIN}
      postgres:
        aliases:
          - vaultwarden.${DOMAIN}
          - app.vaultwarden.${DOMAIN}
      mailserver:
        aliases:
          - vaultwarden.${DOMAIN}
          - app.vaultwarden.${DOMAIN}
      authelia:
        aliases:
          - vaultwarden.${DOMAIN}
          - app.vaultwarden.${DOMAIN}
    depends_on:
      postgres:
        condition: service_started
      mailserver:
        condition: service_started
      authelia:
        condition: service_started
    environment:
      DOMAIN: https://app.vaultwarden.${DOMAIN}
      DATABASE_URL: postgresql://vaultwarden:${VAULTWARDEN_DB_PASSWORD}@postgres:5432/vaultwarden
      SIGNUPS_ALLOWED: false
      SIGNUPS_VERIFY: true
      SIGNUPS_DOMAINS_WHITELIST: ${MAIL_DOMAIN}
      INVITATIONS_ALLOWED: false
      SHOW_PASSWORD_HINT: false
      SSO_ENABLED: true
      SSO_ONLY: true
      SSO_AUTHORITY: https://auth.${DOMAIN}
      SSO_CLIENT_ID: vaultwarden
      SSO_CLIENT_SECRET: ${VAULTWARDEN_OAUTH_SECRET}
      SSO_SCOPES: openid email profile
      SSO_CALLBACK_PATH: /identity/connect/oidc-signin
      SSO_SIGNUPS_MATCH_EMAIL: true
      ADMIN_TOKEN: ${VAULTWARDEN_ADMIN_TOKEN}
      SMTP_HOST: mailserver
      SMTP_FROM: vaultwarden@${MAIL_DOMAIN}
      SMTP_PORT: 587
      SMTP_SECURITY: starttls
      SMTP_USERNAME: vaultwarden@${MAIL_DOMAIN}
      SMTP_PASSWORD: ${VAULTWARDEN_SMTP_PASSWORD}
    volumes:
      - vaultwarden_data:/data
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:80/alive || exit 1"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 60s

  bookstack:
    image: lscr.io/linuxserver/bookstack:version-v24.12.1
    container_name: bookstack
    restart: unless-stopped
    networks:
      caddy:
        aliases:
          - bookstack.${DOMAIN}
      mariadb:
        aliases:
          - bookstack.${DOMAIN}
    depends_on:
      mariadb:
        condition: service_healthy
      mariadb-init:
        condition: service_completed_successfully
    environment:
      PUID: ${DOCKER_USER_ID:-1000}
      PGID: ${DOCKER_GROUP_ID:-1000}
      TZ: UTC
      APP_URL: https://bookstack.${DOMAIN}
      APP_KEY: ${BOOKSTACK_APP_KEY}
      DB_HOST: mariadb
      DB_PORT: 3306
      DB_USER: bookstack
      DB_PASS: ${BOOKSTACK_DB_PASSWORD}
      DB_DATABASE: bookstack
      # Using Caddy forward_auth with Authelia (not OIDC)
    volumes:
      - bookstack_data:/config
      - ./configs/applications/bookstack/init:/custom-cont-init.d:ro
    healthcheck:
      test: ["CMD", "wget", "--no-check-certificate", "--quiet", "--tries=1", "--spider", "http://localhost:80/"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 120s

  planka:
    image: ghcr.io/plankanban/planka:1.26.3
    container_name: planka
    restart: unless-stopped
    networks:
      caddy:
        aliases:
          - planka.${DOMAIN}
      postgres:
        aliases:
          - planka.${DOMAIN}
      authelia:
        aliases:
          - planka.${DOMAIN}
    depends_on:
      postgres-init:
        condition: service_completed_successfully
      authelia:
        condition: service_started
    environment:
      BASE_URL: https://planka.${DOMAIN}
      DATABASE_URL: postgresql://planka:${PLANKA_DB_PASSWORD_ENCODED:-${PLANKA_DB_PASSWORD}}@postgres:5432/planka
      SECRET_KEY: ${PLANKA_SECRET_KEY}
      OIDC_ISSUER: https://auth.${DOMAIN}
      OIDC_CLIENT_ID: planka
      OIDC_CLIENT_SECRET: ${PLANKA_OAUTH_SECRET}
      OIDC_SCOPES: openid profile email groups
      OIDC_ADMIN_ROLES: admins
      OIDC_EMAIL_ATTRIBUTE: email
      OIDC_NAME_ATTRIBUTE: name
      OIDC_USERNAME_ATTRIBUTE: preferred_username
      OIDC_REDIRECT_URI: https://planka.${DOMAIN}/oidc-callback
      OIDC_AUTHORIZATION_ENDPOINT: https://auth.${DOMAIN}/api/oidc/authorization
      OIDC_TOKEN_ENDPOINT: http://authelia:9091/api/oidc/token
      OIDC_USERINFO_ENDPOINT: http://authelia:9091/api/oidc/userinfo
      OIDC_TOKEN_ENDPOINT_AUTH_METHOD: client_secret_post
      OIDC_ENFORCED: false
      NODE_EXTRA_CA_CERTS: /usr/local/share/ca-certificates/caddy-ca.crt
    volumes:
      - planka_data:/app/public/user-avatars
      - ./configs/applications/planka/caddy-ca.crt:/usr/local/share/ca-certificates/caddy-ca.crt:ro
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:1337/"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 60s

  forgejo:
    image: codeberg.org/forgejo/forgejo:9.0
    container_name: forgejo
    restart: unless-stopped
    networks:
      caddy:
        aliases:
          - forgejo.${DOMAIN}
      postgres:
        aliases:
          - forgejo.${DOMAIN}
    depends_on:
      postgres:
        condition: service_started
    environment:
      USER_UID: ${DOCKER_USER_ID:-1000}
      USER_GID: ${DOCKER_GROUP_ID:-1000}
      FORGEJO__database__DB_TYPE: postgres
      FORGEJO__database__HOST: postgres:5432
      FORGEJO__database__NAME: forgejo
      FORGEJO__database__USER: forgejo
      FORGEJO__database__PASSWD: ${FORGEJO_DB_PASSWORD}
      FORGEJO__server__DOMAIN: forgejo.${DOMAIN}
      FORGEJO__server__SSH_DOMAIN: forgejo.${DOMAIN}
      FORGEJO__server__ROOT_URL: https://forgejo.${DOMAIN}/
      FORGEJO__security__INSTALL_LOCK: true
      FORGEJO__service__DISABLE_REGISTRATION: true
      FORGEJO__service__ALLOW_ONLY_EXTERNAL_REGISTRATION: true
      FORGEJO__service__REQUIRE_SIGNIN_VIEW: true
      FORGEJO__oauth2_client__ENABLE_AUTO_REGISTRATION: true
      FORGEJO__openid__ENABLE_OPENID_SIGNIN: true
      FORGEJO__openid__ENABLE_OPENID_SIGNUP: true
      FORGEJO_OAUTH_SECRET: ${FORGEJO_OAUTH_SECRET}
      DOMAIN: ${DOMAIN}
      STACK_ADMIN_PASSWORD: ${STACK_ADMIN_PASSWORD}
      STACK_ADMIN_EMAIL: ${STACK_ADMIN_EMAIL}
    volumes:
      - forgejo_data:/data
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/api/healthz"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 90s

  homepage:
    image: ghcr.io/gethomepage/homepage:v1.8.0
    container_name: homepage
    restart: unless-stopped
    networks:
      caddy:
        aliases:
          - homepage.${DOMAIN}
      docker-proxy:
        aliases:
          - homepage.${DOMAIN}
    depends_on:
      docker-proxy:
        condition: service_started
    environment:
      PUID: ${DOCKER_USER_ID:-1000}
      PGID: ${DOCKER_GROUP_ID:-1000}
      HOMEPAGE_ALLOWED_HOSTS: homepage.${DOMAIN}
      DOCKER_HOST: tcp://docker-proxy:2375
    volumes:
      - ./configs/applications/homepage/services.yaml:/app/config/services.yaml:ro
      - ./configs/applications/homepage/settings.yaml:/app/config/settings.yaml:ro
      - ./configs/applications/homepage/widgets.yaml:/app/config/widgets.yaml:ro
      - ./configs/applications/homepage/bookmarks.yaml:/app/config/bookmarks.yaml:ro
      - ./configs/applications/homepage/docker.yaml:/app/config/docker.yaml:ro
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 30s

  jupyterhub:
    image: datamancy-jupyterhub:5.4.3
    container_name: jupyterhub
    restart: unless-stopped
    networks:
      caddy:
        aliases:
          - jupyterhub.${DOMAIN}
      litellm:
        aliases:
          - jupyterhub.${DOMAIN}
      docker-proxy:
        aliases:
          - jupyterhub.${DOMAIN}
    depends_on:
      dind:
        condition: service_healthy
    environment:
      DOCKER_HOST: tcp://dind:2375
      DOCKER_NETWORK_NAME: datamancy-stack_litellm
      LITELLM_API_KEY: ${LITELLM_MASTER_KEY}
      JUPYTERHUB_CRYPT_KEY: ${JUPYTERHUB_CRYPT_KEY}
    volumes:
      - ./volumes/data/jupyterhub:/srv/jupyterhub
      - ./configs/applications/jupyterhub/jupyterhub_config.py:/srv/jupyterhub/jupyterhub_config.py:ro
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/hub/health || exit 1"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 90s

  homeassistant:
    image: ghcr.io/home-assistant/home-assistant:2026.1.0
    container_name: homeassistant
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      postgres-init:
        condition: service_completed_successfully
      ldap:
        condition: service_healthy
    networks:
      caddy:
        aliases:
          - homeassistant.${DOMAIN}
          - api.homeassistant.${DOMAIN}
      postgres:
        aliases:
          - homeassistant.${DOMAIN}
          - api.homeassistant.${DOMAIN}
      ldap:
        aliases:
          - homeassistant.${DOMAIN}
          - api.homeassistant.${DOMAIN}
    environment:
      TZ: UTC
      PUID: ${DOCKER_USER_ID:-1000}
      PGID: ${DOCKER_GROUP_ID:-1000}
      HOMEASSISTANT_DB_URL: postgresql://homeassistant:${HOMEASSISTANT_DB_PASSWORD}@postgres:5432/homeassistant
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_DB: homeassistant
      POSTGRES_USER: homeassistant
      POSTGRES_PASSWORD: ${HOMEASSISTANT_DB_PASSWORD}
      LDAP_URL: ldap://ldap:389
      STACK_ADMIN_USER: ${STACK_ADMIN_USER}
      STACK_ADMIN_PASSWORD: ${STACK_ADMIN_PASSWORD}
      STACK_ADMIN_EMAIL: ${STACK_ADMIN_EMAIL}
      LDAP_BASE_DN: dc=stack,dc=local
      LDAP_USER_DN: ou=users,dc=stack,dc=local
      LDAP_BIND_DN: cn=admin,dc=stack,dc=local
      LDAP_BIND_PASSWORD: ${LDAP_ADMIN_PASSWORD}
      LDAP_USER_FILTER: (uid={username})
    volumes:
      - ./volumes/data/homeassistant:/config
      - /etc/localtime:/etc/localtime:ro
      - ./configs/applications/homeassistant/configuration.yaml:/config/configuration.yaml:ro
      - ./configs/applications/homeassistant/automations.yaml:/config/automations.yaml:rw
      - ./configs/applications/homeassistant/scripts.yaml:/config/scripts.yaml:rw
      - ./configs/applications/homeassistant/scenes.yaml:/config/scenes.yaml:rw
      - ./configs/applications/homeassistant/init-homeassistant.sh:/init-homeassistant.sh:ro
      - ./configs/applications/homeassistant/entrypoint.sh:/entrypoint-wrapper.sh:ro
      - ./configs/applications/homeassistant/auth_ldap.py:/usr/src/homeassistant/homeassistant/auth/providers/auth_ldap.py:ro
    entrypoint:
      - /entrypoint-wrapper.sh
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8123/manifest.json || exit 1"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 120s

  ntfy:
    image: binwiederhier/ntfy:v2.15.0
    container_name: ntfy
    restart: unless-stopped
    networks:
      caddy:
        aliases:
          - ntfy.${DOMAIN}
    command:
      - serve
    environment:
      TZ: America/New_York
      NTFY_BASE_URL: https://ntfy.${DOMAIN}
      NTFY_CACHE_FILE: /var/lib/ntfy/cache.db
      NTFY_AUTH_FILE: /var/lib/ntfy/auth.db
      NTFY_AUTH_DEFAULT_ACCESS: deny-all
      NTFY_ATTACHMENT_CACHE_DIR: /var/lib/ntfy/attachments
      NTFY_ENABLE_LOGIN: true
    volumes:
      - ntfy_data:/var/lib/ntfy
    healthcheck:
      test: ["CMD-SHELL", "wget -q --tries=1 --spider http://localhost:80/v1/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s

  qbittorrent:
    image: lscr.io/linuxserver/qbittorrent:latest
    container_name: qbittorrent
    restart: unless-stopped
    networks:
      caddy:
        aliases:
          - qbittorrent.${DOMAIN}
    environment:
      PUID: ${DOCKER_USER_ID:-1000}
      PGID: ${DOCKER_GROUP_ID:-1000}
      TZ: UTC
      WEBUI_PORT: 8080
    volumes:
      - qbittorrent_config:/config
      - qbittorrent_data:/downloads
      - ./configs/applications/qbittorrent/init:/custom-cont-init.d:ro
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:8080/"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 30s

  synapse-init:
    image: alpine:latest
    container_name: synapse-init
    restart: no
    networks:
      - postgres
    volumes:
      - ./volumes/data/synapse:/data
      - ./configs/applications/synapse/entrypoint.sh:/tmp/entrypoint.sh:ro
    command:
      - sh
      - -c
      - |
        echo "Copying entrypoint and fixing Synapse volume ownership..."
        cp /tmp/entrypoint.sh /data/entrypoint.sh
        chmod +x /data/entrypoint.sh
        chown -R 991:991 /data
        echo "Synapse volume permissions fixed (UID:GID = 991:991)"


  synapse:
    image: matrixdotorg/synapse:v1.144.0
    container_name: synapse
    restart: unless-stopped
    networks:
      caddy:
        aliases:
          - matrix.${DOMAIN}
          - api.matrix.${DOMAIN}
      postgres:
        aliases:
          - matrix.${DOMAIN}
          - api.matrix.${DOMAIN}
      valkey:
        aliases:
          - matrix.${DOMAIN}
          - api.matrix.${DOMAIN}
      ldap:
        aliases:
          - matrix.${DOMAIN}
          - api.matrix.${DOMAIN}
      matrix-internal:
        aliases:
          - matrix.${DOMAIN}
          - api.matrix.${DOMAIN}
      authelia:
        aliases:
          - matrix.${DOMAIN}
          - api.matrix.${DOMAIN}
    depends_on:
      postgres:
        condition: service_started
      synapse-init:
        condition: service_completed_successfully
      valkey:
        condition: service_started
      ldap:
        condition: service_started
    environment:
      DOMAIN: ${DOMAIN}
      SYNAPSE_SERVER_NAME: matrix.${DOMAIN}
      SYNAPSE_REPORT_STATS: yes
      SYNAPSE_ENABLE_REGISTRATION: ${MATRIX_ENABLE_REGISTRATION:-false}
      SYNAPSE_TRUSTED_PROXIES: 172.18.0.0/16,172.21.0.0/24
      SYNAPSE_LOG_LEVEL: WARNING
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_DB: synapse
      POSTGRES_USER: synapse
      POSTGRES_PASSWORD: ${SYNAPSE_DB_PASSWORD}
      SYNAPSE_DB_PASSWORD: ${SYNAPSE_DB_PASSWORD}
      SYNAPSE_REGISTRATION_SECRET: ${SYNAPSE_REGISTRATION_SECRET}
      SYNAPSE_MACAROON_SECRET: ${SYNAPSE_MACAROON_SECRET}
      SYNAPSE_FORM_SECRET: ${SYNAPSE_FORM_SECRET}
      MATRIX_OAUTH_SECRET: ${MATRIX_OAUTH_SECRET}
      REDIS_HOST: redis-synapse
      LDAP_ADMIN_PASSWORD: ${LDAP_ADMIN_PASSWORD}
      UID: 991
      GID: 991
    entrypoint: ["/data/entrypoint.sh"]
    volumes:
      - ./volumes/data/synapse:/data
      - ./configs/applications/synapse/homeserver.yaml:/data/homeserver.yaml:ro
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8008/health || exit 1"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 120s

  element:
    image: vectorim/element-web:v1.11.91
    container_name: element
    restart: unless-stopped
    networks:
      caddy:
        aliases:
          - element.${DOMAIN}
      matrix-internal:
        aliases:
          - element.${DOMAIN}
    depends_on:
      synapse:
        condition: service_started
    volumes:
      - element_data:/app/config
      - ./configs/applications/element/config.json:/app/config.json:ro
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:80/"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 30s

  mastodon-init:
    image: ghcr.io/mastodon/mastodon:v4.5.4
    container_name: mastodon-init
    restart: no
    networks:
      - postgres
      - valkey
    depends_on:
      postgres-init:
        condition: service_completed_successfully
      valkey:
        condition: service_started
    environment:
      LOCAL_DOMAIN: ${DOMAIN}
      RAILS_ENV: production
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: mastodon
      DB_USER: mastodon
      DB_PASS: ${MASTODON_DB_PASSWORD}
      REDIS_HOST: valkey
      REDIS_PORT: 6379
      SECRET_KEY_BASE: ${MASTODON_SECRET_KEY_BASE}
      OTP_SECRET: ${MASTODON_OTP_SECRET}
      VAPID_PRIVATE_KEY: ${MASTODON_VAPID_PRIVATE_KEY}
      VAPID_PUBLIC_KEY: ${MASTODON_VAPID_PUBLIC_KEY}
      ACTIVE_RECORD_ENCRYPTION_DETERMINISTIC_KEY: ${MASTODON_ACTIVE_RECORD_ENCRYPTION_DETERMINISTIC_KEY}
      ACTIVE_RECORD_ENCRYPTION_KEY_DERIVATION_SALT: ${MASTODON_ACTIVE_RECORD_ENCRYPTION_KEY_DERIVATION_SALT}
      ACTIVE_RECORD_ENCRYPTION_PRIMARY_KEY: ${MASTODON_ACTIVE_RECORD_ENCRYPTION_PRIMARY_KEY}
    command:
      - bash
      - -c
      - |
        echo "Running Mastodon database migrations..."
        bundle exec rails db:migrate
        echo "Mastodon database migrations complete"
        

  mastodon-web:
    image: ghcr.io/mastodon/mastodon:v4.5.4
    container_name: mastodon-web
    restart: unless-stopped
    networks:
      - caddy
      - postgres
      - valkey
      - mastodon-internal
    depends_on:
      mastodon-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
      valkey:
        condition: service_healthy
    environment:
      LOCAL_DOMAIN: ${DOMAIN}
      WEB_DOMAIN: mastodon.${DOMAIN}
      RAILS_ENV: production
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: mastodon
      DB_USER: mastodon
      DB_PASS: ${MASTODON_DB_PASSWORD}
      REDIS_HOST: valkey
      REDIS_PORT: 6379
      SECRET_KEY_BASE: ${MASTODON_SECRET_KEY_BASE}
      OTP_SECRET: ${MASTODON_OTP_SECRET}
      VAPID_PRIVATE_KEY: ${MASTODON_VAPID_PRIVATE_KEY}
      VAPID_PUBLIC_KEY: ${MASTODON_VAPID_PUBLIC_KEY}
      ACTIVE_RECORD_ENCRYPTION_DETERMINISTIC_KEY: ${MASTODON_ACTIVE_RECORD_ENCRYPTION_DETERMINISTIC_KEY}
      ACTIVE_RECORD_ENCRYPTION_KEY_DERIVATION_SALT: ${MASTODON_ACTIVE_RECORD_ENCRYPTION_KEY_DERIVATION_SALT}
      ACTIVE_RECORD_ENCRYPTION_PRIMARY_KEY: ${MASTODON_ACTIVE_RECORD_ENCRYPTION_PRIMARY_KEY}
      SMTP_SERVER: mailserver
      SMTP_PORT: 587
      SMTP_FROM_ADDRESS: mastodon@${DOMAIN}
      SMTP_AUTH_METHOD: plain
      SMTP_OPENSSL_VERIFY_MODE: none
      STREAMING_API_BASE_URL: wss://mastodon.${DOMAIN}
      WEB_CONCURRENCY: 2
      MAX_THREADS: 5
      # Rails configuration
      RAILS_MAX_THREADS: 5
      DB_POOL: 10  # Should be >= MAX_THREADS for connection pooling
      # Trust all Docker bridge networks for X-Forwarded-* headers
      TRUSTED_PROXY_IP: 172.16.0.0/12  # Docker default bridge range (172.16-31.x.x)
    command: bash -c "bundle exec rails server -b 0.0.0.0"
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/health"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 120s

  mastodon-streaming:
    image: ghcr.io/mastodon/mastodon-streaming:v4.5.4
    container_name: mastodon-streaming
    restart: unless-stopped
    networks:
      - postgres
      - valkey
      - mastodon-internal
    depends_on:
      postgres:
        condition: service_started
      valkey:
        condition: service_started
    environment:
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: mastodon
      DB_USER: mastodon
      DB_PASS: ${MASTODON_DB_PASSWORD}
      REDIS_HOST: valkey
      REDIS_PORT: 6379
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:4000/api/v1/streaming/health"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 60s

  mastodon-sidekiq:
    image: ghcr.io/mastodon/mastodon:v4.5.4
    container_name: mastodon-sidekiq
    restart: unless-stopped
    networks:
      - postgres
      - valkey
      - mastodon-internal
    depends_on:
      mastodon-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
      valkey:
        condition: service_healthy
    environment:
      LOCAL_DOMAIN: ${DOMAIN}
      WEB_DOMAIN: mastodon.${DOMAIN}
      RAILS_ENV: production
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: mastodon
      DB_USER: mastodon
      DB_PASS: ${MASTODON_DB_PASSWORD}
      REDIS_HOST: valkey
      REDIS_PORT: 6379
      SECRET_KEY_BASE: ${MASTODON_SECRET_KEY_BASE}
      OTP_SECRET: ${MASTODON_OTP_SECRET}
      VAPID_PRIVATE_KEY: ${MASTODON_VAPID_PRIVATE_KEY}
      VAPID_PUBLIC_KEY: ${MASTODON_VAPID_PUBLIC_KEY}
      ACTIVE_RECORD_ENCRYPTION_DETERMINISTIC_KEY: ${MASTODON_ACTIVE_RECORD_ENCRYPTION_DETERMINISTIC_KEY}
      ACTIVE_RECORD_ENCRYPTION_KEY_DERIVATION_SALT: ${MASTODON_ACTIVE_RECORD_ENCRYPTION_KEY_DERIVATION_SALT}
      ACTIVE_RECORD_ENCRYPTION_PRIMARY_KEY: ${MASTODON_ACTIVE_RECORD_ENCRYPTION_PRIMARY_KEY}
      SMTP_SERVER: mailserver
      SMTP_PORT: 587
      SMTP_FROM_ADDRESS: mastodon@${DOMAIN}
      SMTP_AUTH_METHOD: plain
      SMTP_OPENSSL_VERIFY_MODE: none
    command: bundle exec sidekiq
    healthcheck:
      test: ["CMD-SHELL", "ps aux | grep -v grep | grep 'sidekiq'"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 60s

  roundcube-init:
    image: postgres:16.11
    container_name: roundcube-init
    restart: no
    networks:
      - postgres
    depends_on:
      postgres-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
    environment:
      PGPASSWORD: ${POSTGRES_ROOT_PASSWORD}
      POSTGRES_USER: ${STACK_ADMIN_USER}
      ROUNDCUBE_DB_PASSWORD: ${ROUNDCUBE_DB_PASSWORD}
    volumes:
      - ./configs/databases/postgres/roundcube-schema.sql:/tmp/roundcube-schema.sql:ro
    command:
      - bash
      - -c
      - |
        echo "Initializing Roundcube database schema..."

        # Wait for postgres to be ready
        until pg_isready -h postgres -U ${STACK_ADMIN_USER}; do
          echo "Waiting for postgres..."
          sleep 2
        done

        # Check if session table already exists
        TABLE_EXISTS=$$(PGPASSWORD="$$PGPASSWORD" psql -h postgres -U "$$POSTGRES_USER" -d roundcube -tAc "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'session');")

        if [ "$$TABLE_EXISTS" = "t" ]; then
          echo "Roundcube schema already initialized, skipping..."
          exit 0
        fi

        echo "Applying Roundcube schema from bundled file..."
        PGPASSWORD="$$PGPASSWORD" psql -h postgres -U "$$POSTGRES_USER" -d roundcube -f /tmp/roundcube-schema.sql

        echo "Granting permissions to roundcube user..."
        PGPASSWORD="$$PGPASSWORD" psql -h postgres -U "$$POSTGRES_USER" -d roundcube <<-EOSQL
          GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO roundcube;
          GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public TO roundcube;
        EOSQL

        echo "Roundcube database schema initialized successfully!"

  roundcube:
    image: roundcube/roundcubemail:latest
    container_name: roundcube
    restart: unless-stopped
    networks:
      - caddy
      - mailserver
      - postgres
    depends_on:
      mailserver:
        condition: service_started
      postgres:
        condition: service_started
      roundcube-init:
        condition: service_completed_successfully
    environment:
      ROUNDCUBEMAIL_DB_TYPE: pgsql
      ROUNDCUBEMAIL_DB_HOST: postgres
      ROUNDCUBEMAIL_DB_PORT: 5432
      ROUNDCUBEMAIL_DB_USER: roundcube
      ROUNDCUBEMAIL_DB_PASSWORD: ${ROUNDCUBE_DB_PASSWORD}
      ROUNDCUBEMAIL_DB_NAME: roundcube
      ROUNDCUBEMAIL_DEFAULT_HOST: mailserver
      ROUNDCUBEMAIL_DEFAULT_PORT: 143
      ROUNDCUBEMAIL_SMTP_SERVER: mailserver
      ROUNDCUBEMAIL_SMTP_PORT: 587
      ROUNDCUBEMAIL_UPLOAD_MAX_FILESIZE: 50M
    volumes:
      - roundcube_data:/var/www/html
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:80/ || exit 1"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 60s

  radicale:
    image: tomsquest/docker-radicale:latest
    container_name: radicale
    restart: unless-stopped
    networks:
      - caddy
    environment:
      TZ: UTC
    volumes:
      - radicale_data:/data
      - ./configs/applications/radicale/config:/etc/radicale/config:ro
      - ./configs/applications/radicale/users:/data/users
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:5232/.web/"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 30s

  seafile:
    image: seafileltd/seafile-mc:13.0.15
    container_name: seafile
    restart: unless-stopped
    networks:
      caddy:
        aliases:
          - seafile.${DOMAIN}
          - api.seafile.${DOMAIN}
      mariadb:
        aliases:
          - seafile.${DOMAIN}
          - api.seafile.${DOMAIN}
      memcached:
        aliases:
          - seafile.${DOMAIN}
          - api.seafile.${DOMAIN}
      valkey:
        aliases:
          - seafile.${DOMAIN}
    depends_on:
      mariadb:
        condition: service_healthy
      mariadb-init:
        condition: service_completed_successfully
      seafile-memcached:
        condition: service_started
      valkey:
        condition: service_healthy
    environment:
      TZ: UTC
      DB_HOST: mariadb
      DB_ROOT_PASSWD: ${MARIADB_ROOT_PASSWORD}
      SEAFILE_MYSQL_DB_HOST: mariadb
      SEAFILE_MYSQL_DB_PORT: 3306
      SEAFILE_MYSQL_DB_USER: seafile
      SEAFILE_MYSQL_DB_PASSWORD: ${MARIADB_SEAFILE_PASSWORD}
      INIT_SEAFILE_MYSQL_ROOT_PASSWORD: ${MARIADB_ROOT_PASSWORD}
      SEAFILE_SERVER_HOSTNAME: seafile.${DOMAIN}
      SEAFILE_ADMIN_EMAIL: ${STACK_ADMIN_EMAIL}
      SEAFILE_ADMIN_PASSWORD: ${STACK_ADMIN_PASSWORD}
      JWT_PRIVATE_KEY: ${SEAFILE_JWT_KEY}
      TIME_ZONE: UTC
      CACHE_PROVIDER: redis
      REDIS_HOST: valkey
      REDIS_PORT: 6379
    volumes:
      - seafile_files:/shared
      - seafile_media:/shared/seafile/library-template
    healthcheck:
      test: ["CMD", "curl", "-f", "-s", "http://localhost:80/api2/ping/"]
      interval: 60s
      timeout: 20s
      retries: 3
      start_period: 180s

  onlyoffice:
    image: onlyoffice/documentserver:8.3.3
    container_name: onlyoffice
    restart: unless-stopped
    networks:
      caddy:
        aliases:
          - onlyoffice.${DOMAIN}
    environment:
      JWT_ENABLED: true
      JWT_SECRET: ${ONLYOFFICE_JWT_SECRET}
    volumes:
      - onlyoffice_data:/var/www/onlyoffice
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:80/healthcheck"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 120s

