# AI/ML services
# vLLM, LiteLLM, embedding service

services:
  vllm:
    image: vllm/vllm-openai:latest
    container_name: vllm
    restart: unless-stopped
    networks:
      - backend
    environment:
      - HUGGINGFACEHUB_API_TOKEN=${HUGGINGFACEHUB_API_TOKEN}
      - HF_HUB_ENABLE_HF_TRANSFER=0
    command: [
      "Qwen/Qwen2.5-0.5B-Instruct",
      "--served-model-name", "qwen2.5-0.5b",
      "--max-model-len", "2048",
      "--max-num-seqs", "64",
      "--dtype", "auto",
      "--enable-auto-tool-choice",
      "--tool-call-parser", "hermes",
      "--gpu-memory-utilization", "0.3"
    ]
    volumes:
      - ${VOLUMES_ROOT}/vllm/hf-cache:/root/.cache/huggingface
    deploy:
      resources:
        limits:
          memory: 16G
          cpus: '12.0'
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 60s
      timeout: 10s
      retries: 5
      start_period: 2m

  embedding-service:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.2
    container_name: embedding-service
    restart: unless-stopped
    networks:
      - backend
    command: --model-id sentence-transformers/all-MiniLM-L6-v2 --port 8080
    volumes:
      - ${VOLUMES_ROOT}/embeddings/models:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  litellm:
    image: ghcr.io/berriai/litellm:v1.74.9-stable.patch.1
    container_name: litellm
    restart: unless-stopped
    networks:
      - backend
      - frontend
    depends_on:
      - vllm
    volumes:
      - litellm_config:/app/config
      - ${HOME}/.datamancy/configs/infrastructure/litellm/config.yaml:/app/config.yaml:ro
    environment:
      - LITELLM_MASTER_KEY=${LITELLM_MASTER_KEY}
      - UI_USERNAME=${STACK_ADMIN_USER}
      - UI_PASSWORD=${STACK_ADMIN_PASSWORD}
    command: --config /app/config.yaml --port 4000 --num_workers 4
    healthcheck:
      test: ["CMD", "wget", "-q", "-O", "/dev/null", "http://localhost:4000/health/readiness"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 15s
