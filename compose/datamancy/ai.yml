# Auto-generated from services.registry.yaml
# DO NOT EDIT MANUALLY - run scripts/codegen/generate-compose.main.kts

services:
  vllm:
    image: vllm/vllm-openai:latest
    container_name: vllm
    networks:
      ai: {}
    healthcheck:
      # Using Docker HEALTHCHECK from image
      interval: 60s
      timeout: 10s
      retries: 5
      start_period: 2m
    deploy:
      resources:
        limits:
          memory: 16G
          cpus: '12.0'

  embedding-service:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.2
    container_name: embedding-service
    networks:
      ai: {}
      ai-gateway: {}
    healthcheck:
      # Using Docker HEALTHCHECK from image
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  litellm:
    image: ghcr.io/berriai/litellm:v1.74.9-stable.patch.1
    container_name: litellm
    networks:
      ai:
        aliases:
          - litellm.${DOMAIN}
          - api.litellm.${DOMAIN}
      frontend:
        aliases:
          - litellm.${DOMAIN}
          - api.litellm.${DOMAIN}
    depends_on:
      - vllm
    healthcheck:
      # Using Docker HEALTHCHECK from image
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 15s

